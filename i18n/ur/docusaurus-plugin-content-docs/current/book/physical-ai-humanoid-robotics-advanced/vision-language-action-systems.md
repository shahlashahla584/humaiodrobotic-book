---
sidebar_position: 8
---

import UrduTranslateButton from '@site/src/components/UrduTranslateButton';

<UrduTranslateButton />

# ویڑن-زبان-عمل سسٹم

## سیکھنے کے مقاصد
اس فصل کے آخر تک، طلباء مندرجہ ذیل کر سکیں گے:
- ویڑن-زبان ماڈلز (VLMs) اور ویڑن زبان عمل (VLA) سسٹم کے معماری کے اجزاء کی وضاحت کریں۔
- سمجھیں کہ VLAs روبوٹس کو قدرتی زبان کے حکم کو تشریح کرنے اور انہیں بصری ادراک میں زمین کے ساتھ کیسے فعال کرتے ہیں۔
- VLA چلائے گئے روبوٹکس میں پرامپٹ انجینئرنگ اور چند شاٹ سیکھنے کی تکنیکوں کی وضاحت کریں۔
- پیچیدہ، کھلے اختتام والے روبوٹک کاموں کے لیے VLAs استعمال کرنے میں چیلنجز اور مواقع پر تبادلہ خیال کریں۔
- VLAs کی حقیقی دنیا کی مثالوں کا تجزیہ کریں جو روبوٹ کی صلاحیتوں کو بہتر بناتے ہیں۔

## ویڑن-زبان-عمل (VLA) سسٹم کا تعارف
روایتی روبوٹ پروگرامنگ اکثر ہر کام اور منظر کے لیے صریح کوڈنگ کی ضرورت ہوتی ہے۔ ویڑن-زبان-عمل (VLA) سسٹم ایک نقطہ نظر کی تبدیلی کی نمائندگی کرتے ہیں، جو روبوٹس کو قدرتی زبان کے حکم کو سمجھنے اور انجام دینے کی اجازت دیتے ہیں جب وہ بصری ادراک کے ساتھ زبان کی سمجھ کو ضم کرتے ہیں۔ یہ سسٹم انسانوں کے مطابق ماحول میں روبوٹس کو زیادہ محسوس، موافقت پذیر، اور صلاحیت والے بنانے کے لیے اہم ہیں۔

## ویڑن-زبان ماڈلز (VLMs) سے VLAs تک

### ویڑن-زبان ماڈلز (VLMs)
VLMs ایسے نیورل نیٹ ورک ہیں جو بصری (تصاویر، ویڈیو) اور متن کی معلومات کو پروسیس کر سکتے ہیں اور سمجھ سکتے ہیں۔ وہ الفاظ اور جملوں کو بصری تصورات کے ساتھ منسلک کرنا سیکھتے ہیں، جس سے تصویر کی وضاحت، بصری سوال جواب، اور صفر-شاٹ اشیا کی پہچان جیسے کاموں کو فعال کرتے ہیں۔

- **مارچیکچر:** عام طور پر ایک بصری انکوڈر (جیسے، ایک CNN یا ویڑن ٹرانسفارمر) کو تصاویر پروسیس کرنے، ایک زبانی انکوڈر (جیسے، ٹرانسفارمر-مبنی LLM) کو متن پروسیس کرنے، اور ایک فیوژن میکنزم کو دونوں موڈلز سے معلومات کو ضم کرنے کے لیے شامل کرتے ہیں۔
  *ڈائریم: ویڑن-زبان ماڈل کی آسان مارچیکچر*

### ویڑن زبان عمل (VLA) سسٹم
VLAs VLMs کو وسعت دیتے ہیں ایک "عمل" جزو کا اضافہ کر کے، جو سسٹم کو زبان-زمین والے بصری سمجھ کو روبوٹ کے لیے قابلِ عمل حکم میں تبدیل کرنے کی اجازت دیتا ہے۔ یہ اکثر امیج زبان کے ہدایات کو کم سطحی موٹر حکموں یا علامتی منصوبوں میں میپ کرنے میں شامل ہوتا ہے۔

- **اہم خیال:** انسانی زبان اور روبوٹ کی صلاحیتوں کے درمیان معنی کا فرق پُر کرنا، جس سے روبوٹ کام کے بارے میں زیادہ امیج کے امکان میں سوچ سکیں۔

## روبوٹکس کے لیے VLA سسٹم کی معماری
روبوٹکس کے لیے ایک معمولی VLA سسٹم میں شامل ہو سکتا ہے:
1.  **زبانی فرنٹ اینڈ:** انسانی صارف سے قدرتی زبان کے حکم کو پروسیس کرتا ہے۔
2.  **بصری ادراک ماڈیول:** کیمرے اور VLMs کا استعمال کر کے منظر کی تشریح، اشیاء کی پہچان، اور ان کی خصوصیات اور رشتے کو سمجھنے کے لیے استعمال کرتا ہے۔
3.  **زبان سے عمل کی زمین ماڈیول:** قدرتی زبان کے حکم کو، بصری ادراک کی معلومات کے ساتھ، ایک ترتیب میں قابلِ عمل روبوٹ اقدامات یا ایک بلند سطحی منصوبہ میں تبدیل کرتا ہے۔
4.  **موشن منصوبہ بندی اور کنٹرول:** تصادم سے پاک ٹریجکٹریز کو جنریٹ کرتا ہے اور مطلوبہ عمل کو انجام دینے کے لیے درست موٹر حکم انجام دیتا ہے (متعلقہ: advanced/humanoid-locomotion-control.md)۔
5.  **فیڈ بیک لوپ:** اقدام کے انجام دہی کو مانیٹر کرنے اور سسٹم کی سمجھ کو اپ ڈیٹ کرنے کے لیے حسی ڈیٹا (بصری، پروپریوسیپٹو) استعمال کرتا ہے۔

## روبوٹک کاموں کے لیے پرامپٹ انجینئرنگ
بڑے زبانی ماڈلز میں عام پرامپٹ انجینئرنگ، VLA کے ساتھ مؤثر طریقے سے بات چیت کرنے کے لیے اہم ہے۔ یہ VLA کے رویے کو ہدایت کرنے کے لیے درست اور معلوماتی متنی پرامپٹس تیار کرنے میں شامل ہوتا ہے۔

- **صفر-شاٹ سیکھنا:** VLA مخصوص کام پر صریح تربیت کے بغیر ایک کام انجام دے سکتا ہے، اس کے وسیع پیش تربیت شدہ علم پر انحصار کر کے۔
- **چند-شاٹ سیکھنا:** ایک نئے کام کے لیے VLA کو مطلوبہ رویے کی طرف لے جانے کے لیے پرامپٹ کے اندر چند مثالیں فراہم کرنا۔

```python
# مثال: VLA چلائے گئے روبوٹ کے لیے تصوراتی پرامپٹ
# فرض کریں کہ ایک VLA API جو ایک تصویر اور ایک متنی پرامپٹ لیتا ہے

def robot_command_with_vla(image, prompt_text):
    # VLA پروسیسنگ کی تقلید
    print(f"روبوٹ دیکھتا ہے: [VLM کے ذریعہ تیار کردہ تصویری مواد کی وضاحت]")
    print(f"کمانڈ کی پروسیسنگ: \"{prompt_text}\" ")

    if "red mug اٹھاؤ" in prompt_text.lower():
        return "MOVE_TO_RED_MUG", "GRASP"
    elif "blue object کو ٹیبل پر رکھو" in prompt_text.lower():
        return "MOVE_TO_BLUE_OBJECT", "PICK_UP", "MOVE_TO_TABLE", "PLACE"
    else:
        return "UNKNOWN_COMMAND"

# تقلید شدہ تصویری ڈیٹا
simulated_image_data = "ایک کچن کاؤنٹر کی تصویر جس میں ایک red mug اور ایک blue bowl ہے۔"

# صفر-شاٹ کمانڈ
command_1 = "Red mug اٹھاؤ۔"
actions_1 = robot_command_with_vla(simulated_image_data, command_1)
print(f"روبوٹ اقدامات: {actions_1}\n")

# مزید پیچیدہ کمانڈ (بصری معلومات کی زمین کی ضرورت ہوتی ہے)
command_2 = "Blue object کو ٹیبل پر رکھو۔"
actions_2 = robot_command_with_vla(simulated_image_data, command_2)
print(f"روبوٹ اقدامات: {actions_2}\n")
```

## جسمانی اقدامات میں زبان کی زمین
ایک اہم چیلنج یہ ہے کہ امیج کی زبان کو مکمل روبوٹ حرکات میں زمین کرنا ہے۔ اس میں یہ شامل ہے:
- **اشیاء کا حوالہ:** تعین کرنا کہ انسان منظر میں کون سی مخصوص چیز کا حوالہ دے رہا ہے۔
- **مقامی استدلال:** مقامی رشتے کو سمجھنا (جیسے، "اوپر", "اگل", "نیچے")۔
- **کاروائی کی پہچان:** اشیاء کی خصوصیات اور کام کی بنیاد پر یہ استدلال کرنا کہ کون سے اقدامات اشیاء کے ساتھ کیے جا سکتے ہیں۔
- **مہارت کا سلسلہ:** اعلی سطح کے حکم کو بنیادی روبوٹ مہارتوں کی ترتیب میں توڑنا (جیسے، "اٹھانا اور رکھنا" -> پہنچنا، پکڑنا، اٹھانا، منتقل کرنا، چھوڑنا)۔

## چیلنجز اور مواقع

### چیلنجز
- **اہمیت:** قدرتی زبان اساساً اہم ہے، جس کے لیے مضبوط اہمیت دور کرنے کی حکمت عمل کی ضرورت ہوتی ہے۔
- **عام بوداری:** یہ یقینی بنانا کہ VLA نئی اشیاء، ماحول، اور ان کے تربیتی ڈیٹا سے باہر کے کاموں تک عام بوداری کر سکیں۔
- **حفاطت:** روبوٹس کو غلط تفہیم کی بنیاد پر غیر محفوظ یا غیر منصوبہ بند عمل انجام دینے سے روکنا۔
- **کمپیوٹیشنل لاگت:** VLMs اور VLA کمپیوٹیشنل طور پر کثیر کوشش ہیں، تربیت اور استدلال کے لیے نمایاں وسائل کی ضرورت ہوتی ہے۔
- **حقیقی وقت کی کارکردگی:** تفاعلی روبوٹک کاموں کے لیے کم-مہلک جوابات حاصل کرنا۔

### مواقع
- **محسوس انسان-روبوٹ تعامل:** اندرونی صارفین کو روزمرہ کی زبان کا استعمال کرتے ہوئے روبوٹس کمانے کی اجازت دینا۔
- **کام کی تیز تعیناتی:** وسیع دوبارہ پروگرامنگ کے بغیر روبوٹس کو نئے کام سکھانا۔
- **موافقت پذیری:** روبوٹ تبدیل ہوتے ماحول اور کام کی ضروریات کے مطابق موافقت کر سکتے ہیں۔
- **روبوٹکس کے لیے فاؤنڈیشن ماڈلز:** VLA روبوٹس کو انٹرنیٹ کی سطح کے ڈیٹا کا فائدہ اٹھانے کی اجازت دینے والے طاقتور فاؤنڈیشن ماڈلز کے طور پر کام کر سکتے ہیں۔

## حقیقی دنیا کی مثالیں
- **گوگل کا PaLM-E:** ایک VLM جو ایک روبوٹکس کنٹرول سسٹم کے ساتھ ضم ہے، جو روبوٹ کو طویل افق، پیچیدہ ہدایات (جیسے، "میز کے ڈراور سے چپس لاؤ") انجام دینے کی اجازت دیتا ہے۔
- **OpenAI کی روبوٹکس کی کاوشیں:** ابتدائی کام نے بڑے زبانی ماڈلز کی صلاحیت کو روبوٹ کے رویے کی رہنمائی کے لیے دکھایا۔
- **NVIDIA کا پروجیکٹ GR00T:** ہیومنوائڈ روبوٹس کے لیے ایک بنیادی ماڈل جو انہیں قدرتی زبان کو سمجھنے اور مختلف ان پٹس سے مہارت سیکھنے کے قابل بنانے کے لیے ڈیزائن کیا گیا ہے۔

یہ مثالیں VLAs کی تبدیلی کی صلاحیت کو ظاہر کرتی ہیں تاکہ ہم متنوع اطلاقوں میں روبوٹس کے ساتھ بات چیت کرنے اور ان کو تعینات کرنے کے طریقے میں انقلاب لائیں۔

## مشقیں
1.  روبوٹکس کے تناظر میں ایک معیاری ویڑن-زبان ماڈل (VLM) اور ایک ویڑن-زبان-عمل (VLA) سسٹم کے درمیان کلیدی معماری کے فرق کی وضاحت کریں۔ VLA نے کون سا اہم جزو شامل کیا؟
2.  VLA چلائے گئے روبوٹ کے لیے "جسمانی اقدامات میں زبان کی زمین" کے تصور کی وضاحت کریں۔ قدرتی زبان کے حکم کی ایک سادہ مثال اور یہ دیکھیں کہ اس کو روبوٹ کے اقدامات کی ترتیب میں کیسے زمین کیا جا سکتا ہے۔
3.  پرامپٹ انجینئرنگ اور چند شاٹ سیکھنے کا استعمال کیسے کیا جا سکتا ہے تاکہ بے حد دوبارہ تربیت کے بغیر VLA پاور والے روبوٹ کو نئے کام سکھائے جا سکیں؟ ایک مثال دیں۔
4.  حقیقی دنیا کے ہیومنوائڈ روبوٹس میں VLA سسٹم کو تعینات کرنے میں دو نمایاں چیلنجز پر تبادلہ خیال کریں اور ہر ایک کے لیے ممکنہ کم کرنے والی حکمت عمل کا اظہار کریں۔
5.  روبوٹکس کے لیے ویڑن-زبان-عمل سسٹم پر ایک حالیہ اکادمک پیپر یا صنعتی پروجیکٹ (جن کا ذکر نہیں کیا گیا ہے) کی تحقیق کریں۔ اس کی اہم شراکت کو خلاصہ کریں اور یہ دیکھیں کہ یہ شعبے کو کیسے آگے بڑھاتا ہے۔